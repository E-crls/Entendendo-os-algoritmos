<p align="center">
  <a href="[https://github.com/E-crls/Entendendo-os-algoritmos]">
    <img src="./images/guia.png" alt="O guia para te ajudar a entender melhor data science" width="160" height="160">
  </a>
  <h1 align="center">O guia para te ajudar a entender melhor data science</h1>
</p>

> Este repositório possui como objetivo ajudar no entendimento dos algoritmos usados atualmente em Data Science

## Contribua
> A ideia do repositório é ajudar pessoas que possuem interesses em entender melhor a área de data science através dos algoritmos. Sendo assim, será de enorme valor para quem quiser contribuir com conhecimento.
> Como funciona: 
>   Se você entendeu melhor algum algoritmo específico ou alguma parte específica por meio de determinada explicação, escreva aqui a explicação que te ajudou.
>   Se você está estudando algum algoritmo pouco conhecido, publique uma explicação sobre ele da forma que você conseguir. Nós também aprendemos explicando

Conhecimento é bom, mas conhecimento com facilidade de acesso é melhor ainda.

## Estrutura de explicação
Cada algoritmo irá responder cada uma dos seguintes tópicos, podendo ter outros conforme o tempo:
>Descrição simples<br>
>Descrição técnica<br>
>O que faz<br>
>Onde é mais aplicado (Exemplos de aplicações mais usadas)<br>
>Quando usar (Quando eu estiver sobre quais situações deverei usar este algoritmo?)<br>
>Como usar<br>
>Por que usar<br>
>Recursos necessários (custos para aplicar)<br>
>Diferencial (quais são todas as diferenças entre este modelo de algoritmo para algoritmos com objetivos ou métodos similares a este)<br> 
>Vantagens<br>
>Desvantagens<br>

## Validação das informações
>Todas as informações aqui presentes estão sendo passadas por revisão constante. Sendo assim, se você identificar algum conteúdo errado, sinta-se livre para sugerir a correção.

## Principais algoritmos 
### Algoritmos de aprendizado supervisionado: 

**<br>Regressão Linear 
<br>Regressão Logística 
<br>Máquinas de Vetores de Suporte (SVM) 
<br>k-vizinhos mais próximos (k-NN) 
<br>Árvores de decisão 
<br>Random Forest 
<br>Gradient Boosting 
<br>AdaBoost 
<br>Redes Neurais Artificiais (ANN) 
<br>Redes Neurais Convolucionais (CNN) 
<br>Redes Neurais Recorrentes (RNN) **

### Algoritmos de aprendizado não supervisionado: 

**<br>k-means 
<br>Clustering hierárquico 
<br>DBSCAN 
<br>Modelo de Mistura Gaussiana (GMM) 
<br>PCA (Principal Component Analysis) 
<br>ICA (Independent Component Analysis) 
<br>t-SNE (t-Distributed Stochastic Neighbor Embedding) 
<br>UMAP (Uniform Manifold Approximation and Projection) **

### Algoritmos de aprendizado por reforço: 

**<br>Q-Learning 
<br>SARSA 
<br>Deep Q-Network (DQN) 
<br>Policy Gradients 
<br>Actor-Critic 
<br>Proximal Policy Optimization (PPO) 
<br>Soft Actor-Critic (SAC) **

### Algoritmos de otimização e busca: 

**<br>Gradient Descent 
<br>Stochastic Gradient Descent 
<br>Newton-Raphson **

### Algoritmos Genéticos 

**<br>Particle Swarm Optimization 
<br>Simulated Annealing 
<br>Hill Climbing **

### Algoritmos de processamento de linguagem natural (NLP): 

**<br>TF-IDF 
<br>Word2Vec 
<br>GloVe 
<br>FastText 
<br>BERT 
<br>GPT 
<br>ELMo 
<br>Transformer 
<br>Seq2Seq **

### Algoritmos de recomendação: 

**<br>Collaborative Filtering 
<br>Content-based Filtering 
<br>Hybrid Filtering 
<br>Matrix Factorization (SVD, NMF) 
<br>Deep Learning-based Recommendations **

### Algoritmos de detecção de anomalias: 

**<br>Isolation Forest 
<br>Local Outlier Factor (LOF) 
<br>One-Class SVM 
<br>Autoencoders **

### Algoritmos de redução de dimensionalidade: 

**<br>PCA (Principal Component Analysis) 
<br>LDA (Linear Discriminant Analysis) 
<br>t-SNE (t-Distributed Stochastic Neighbor Embedding) 
<br>UMAP (Uniform Manifold Approximation and Projection) **

### Algoritmos de análise de séries temporais: 

**<br>ARIMA 
<br>SARIMA 
<br>Exponential Smoothing 
<br>Prophet 
<br>LSTM 
<br>GRU **

### Algoritmos de análise de redes e grafos: 

**<br>PageRank 
<br>Shortest Path (Dijkstra, A*, Bellman-Ford) 
<br>Community Detection (Louvain, Girvan-Newman) 
<br>Node2Vec 
<br>Graph Convolutional Networks (GCN) **

## Todos os algoritmos 

### Algoritmos de aprendizado supervisionado: 

<br>**Regressão Linear**: Modelo simples de aprendizado supervisionado para prever uma variável contínua a partir de uma ou mais variáveis independentes. 
<br>**Regressão Polinomial**: Extensão da regressão linear que ajusta um polinômio aos dados. 
<br>**Regressão Ridge**: Versão regularizada da regressão linear que penaliza coeficientes grandes para evitar o sobreajuste. 
<br>Regressão Lasso: Outra versão regularizada da regressão linear que penaliza a soma dos valores absolutos dos coeficientes para evitar o sobreajuste e promover a esparsidade. 
<br>Regressão ElasticNet: Combinação das regularizações L1 e L2, usadas na regressão Lasso e Ridge, respectivamente. 
<br>Regressão Logística: Modelo de classificação binária que estima a probabilidade de um evento ocorrer com base nas variáveis independentes. 
<br>K-vizinhos mais próximos (k-NN): Algoritmo baseado em instâncias que classifica um objeto com base na maioria dos rótulos de seus k vizinhos mais próximos. 
<br>Máquinas de Vetores de Suporte (SVM): Modelo que encontra o hiperplano que melhor separa as classes no espaço de entrada, maximizando a margem entre elas. 
<br>Árvores de decisão: Modelo que aprende regras de decisão a partir dos dados de treinamento, representadas na forma de uma estrutura de árvore. 
<br>Random Forest: Ensemble de árvores de decisão que agrega as previsões de várias árvores treinadas com diferentes subconjuntos de dados e atributos. 
<br>Gradient Boosting: Método de ensemble que combina modelos fracos (geralmente árvores de decisão) de forma sequencial, ajustando cada modelo para os resíduos do modelo anterior. 
<br>XGBoost: Implementação otimizada e escalável do Gradient Boosting, com suporte a paralelização e regularização. 
<br>LightGBM: Método de Gradient Boosting baseado em árvores que cresce verticalmente, escolhendo o nó com o maior ganho de informação para divisão em vez de crescer horizontalmente. 
<br>CatBoost: Algoritmo de Gradient Boosting projetado para lidar com dados categóricos automaticamente, evitando a necessidade de codificação manual. 
<br>Naive Bayes: Modelo probabilístico simples baseado no Teorema de Bayes que assume independência entre os atributos. 
<br>Redes Neurais Artificiais (ANN): Modelo computacional inspirado no cérebro humano, composto por neurônios artificiais interconectados. 
<br>Redes Neurais Convolucionais (CNN): Tipo de ANN projetada para processar dados em grade, como imagens, usando camadas convolucionais para detectar características locais. 
<br>Redes Neurais Recorrentes (RNN): Tipo de ANN projetada para lidar com sequências de dados, onde a saída de um neurônio em um determinado passo de tempo é alimentada de volta como entrada no próximo passo de tempo. 
<br>Long Short-Term Memory (LSTM): Variação de RNN que inclui células de memória para lidar com problemas de dependências de longo prazo e evitar o desaparecimento ou explosão do gradiente. 
<br>Gated Recurrent Units (GRU): Variação de RNN semelhante ao LSTM, mas com uma arquitetura mais simples e menor número de portões de controle. 
<br>Transformer: Modelo de atenção baseado em autoatenção, projetado para lidar com sequências de dados sem a necessidade de recorrência ou convoluções. 
<br>BERT (Bidirectional Encoder Representations from Transformers): Modelo pré-treinado de aprendizado profundo baseado em Transformer para processamento de linguagem natural que considera o contexto bidirecional. 
<br>GPT (Generative Pre-trained Transformer): Modelo pré-treinado de aprendizado profundo baseado em Transformer projetado para geração de texto e outras tarefas de processamento de linguagem natural. 
<br>RoBERTa (Robustly Optimized BERT Pretraining Approach): Variação do BERT que introduz melhorias no pré-treinamento e ajuste fino, resultando em um melhor desempenho. 
<br>DistilBERT: Versão mais leve e rápida do BERT, obtida por destilar conhecimento do modelo BERT original em uma arquitetura menor. 
<br>T5 (Text-to-Text Transfer Transformer): Modelo baseado em Transformer que aborda todas as tarefas de processamento de linguagem natural como um problema de tradução de texto para texto. 
<br>ALBERT (A Lite BERT): Variação do BERT que usa fatorização de parâmetros e compartilhamento de parâmetros entre camadas para reduzir o tamanho do modelo e o tempo de treinamento. 
<br>XLNet: Modelo de linguagem baseado em Transformer que combina a autoatenção bidirecional do BERT com a auto-regressão do GPT para lidar com o contexto e a permutação das palavras. 

### Algoritmos de aprendizado não supervisionado: 

<br>k-means: Algoritmo de clustering que agrupa pontos de dados em k grupos com base na similaridade das características, minimizando a soma das distâncias quadráticas dentro dos grupos. 
<br>Clustering hierárquico: Método de agrupamento que cria uma hierarquia de clusters, permitindo uma visualização em forma de dendrograma. 
<br>DBSCAN: Algoritmo de clustering baseado em densidade que agrupa pontos de dados próximos uns dos outros e identifica outliers com base na densidade. 
<br>OPTICS: Algoritmo de clustering baseado em densidade similar ao DBSCAN, mas que lida melhor com variações na densidade dos clusters. 
<br>Modelo de Mistura Gaussiana (GMM): Algoritmo de clustering baseado em modelos probabilísticos que estima a distribuição de uma mistura de múltiplas distribuições gaussianas. 
<br>PCA (Principal Component Analysis): Técnica de redução de dimensionalidade que transforma os dados em novos eixos, maximizando a variância e minimizando a perda de informações. 
<br>ICA (Independent Component Analysis): Técnica de redução de dimensionalidade que busca componentes independentes não gaussianos nos dados. 
<br>Kernel PCA: Versão não linear do PCA que utiliza funções de kernel para mapear os dados em um espaço de características de maior dimensão antes de aplicar o PCA. 
<br>t-SNE (t-Distributed Stochastic Neighbor Embedding): Técnica de redução de dimensionalidade não linear que preserva a estrutura local e global, projetando os dados em um espaço de menor dimensão, geralmente usado para visualização. 
<br>UMAP (Uniform Manifold Approximation and Projection): Técnica de redução de dimensionalidade não linear que preserva a estrutura local e global, similar ao t-SNE, mas mais rápido e escalável. 
<br>Autoencoders: Redes neurais artificiais treinadas para reconstruir seus próprios inputs, aprendendo uma representação de menor dimensão dos dados no processo. 
<br>Variational Autoencoders (VAE): Tipo de autoencoder que modela uma distribuição probabilística sobre os dados e aprende a gerar novos dados a partir dessa distribuição. 
<br>Restricted Boltzmann Machines (RBM): Redes neurais bipartidas com camadas visíveis e ocultas, utilizadas para aprendizado de características e redução de dimensionalidade. 
<br>Deep Belief Networks (DBN): Redes neurais profundas compostas por múltiplas camadas de RBMs empilhadas, utilizadas para aprendizado de características e redução de dimensionalidade. 
<br>Generative Adversarial Networks (GAN): Modelo de aprendizado profundo composto por duas redes neurais (gerador e discriminador) que competem uma contra a outra para gerar dados realistas a partir de uma distribuição de entrada. 
<br>CycleGAN: Variação do GAN para transformação de imagens entre domínios diferentes sem a necessidade de pares de treinamento correspondentes. 
<br>StyleGAN: Variação do GAN projetado para separar a informação de estilo e conteúdo de imagens, permitindo a geração de imagens com estilo específico.  
<br>Word2Vec: Modelo de aprendizado de representações vetoriais de palavras em um espaço de menor dimensão, capturando a semântica e as relações sintáticas entre as palavras com base no contexto em que aparecem. 
<br>GloVe (Global Vectors for Word Representation): Modelo de aprendizado de representações vetoriais de palavras baseado na co-ocorrência de palavras em um corpus, capturando informações contextuais e semânticas. 
<br>FastText: Modelo de aprendizado de representações vetoriais de palavras que leva em consideração subpalavras ou n-gramas de caracteres, permitindo uma melhor representação de palavras raras e fora do vocabulário. 
<br>ELMo (Embeddings from Language Models): Modelo de aprendizado profundo que gera representações vetoriais de palavras contextualizadas, levando em conta o contexto da palavra dentro de uma frase ou texto. 
<br>Doc2Vec: Extensão do modelo Word2Vec para aprendizado de representações vetoriais de documentos inteiros, levando em consideração a ordem das palavras e o contexto global do documento. 
<br>LDA (Latent Dirichlet Allocation): Modelo probabilístico de tópicos que descobre a estrutura temática latente em uma coleção de documentos, atribuindo tópicos a documentos e palavras a tópicos. 
<br>NMF (Non-negative Matrix Factorization): Método de decomposição de matriz que encontra duas matrizes de baixa dimensão cujo produto aproxima a matriz original, sendo aplicado em aprendizado de características, redução de dimensionalidade e extração de tópicos. Todas as entradas das matrizes são não negativas, refletindo a natureza aditiva dos dados em muitos domínios. 

### Algoritmos de aprendizado por reforço: 

<br>Q-Learning: Um algoritmo de aprendizado por reforço baseado em valores que estima a função de valor-estado-ação (Q) para tomar decisões ideais em um ambiente estocástico. 
<br>SARSA: Um algoritmo similar ao Q-Learning, que se diferencia por atualizar a função Q com base na ação real tomada, em vez da ação ideal (on-policy). 
<br>Deep Q-Network (DQN): Uma extensão do Q-Learning que utiliza redes neurais profundas para estimar a função de valor-estado-ação (Q) em problemas de grande escala. 
<br>Double DQN: Uma melhoria do DQN que aborda o problema de superestimação do valor-estado-ação (Q) usando duas redes neurais separadas. 
<br>Dueling DQN: Uma variação do DQN que utiliza uma arquitetura especial de rede neural para aprender separadamente os valores dos estados e as vantagens das ações. 
<br>Policy Gradients: Um tipo de algoritmo de aprendizado por reforço que aprende diretamente a política de ações ótimas, em vez de estimar valores de estado-ação. 
<br>REINFORCE: Um algoritmo de gradientes de política que utiliza a recompensa de episódios completos para atualizar os parâmetros da política. 
<br>Actor-Critic: Um algoritmo de aprendizado por reforço que combina a abordagem de gradientes de política (ator) e a abordagem baseada em valor (crítico) para melhorar a estabilidade e a convergência. 
<br>A2C (Advantage Actor-Critic): Uma variação do Actor-Critic que utiliza a função de vantagem para melhorar a estimativa de gradientes de política. 
<br>A3C (Asynchronous Advantage Actor-Critic): Uma extensão do A2C que utiliza múltiplos agentes e ambientes paralelos para explorar melhor o espaço de estados e acelerar o treinamento. 
<br>DDPG (Deep Deterministic Policy Gradient): Um algoritmo de aprendizado por reforço contínuo que combina a abordagem Actor-Critic com redes neurais profundas. 
<br>Proximal Policy Optimization (PPO): Um algoritmo de gradientes de política que utiliza uma abordagem de otimização limitada para melhorar a estabilidade e a convergência do treinamento. 
<br>Trust Region Policy Optimization (TRPO): Um algoritmo de gradientes de política que utiliza a otimização de região de confiança para garantir melhorias monotônicas na política durante o treinamento. 
<br>Soft Actor-Critic (SAC): Um algoritmo de aprendizado por reforço contínuo que combina a abordagem Actor-Critic com a otimização de entropia para melhorar a exploração e a estabilidade. 
<br>Rainbow DQN: Uma combinação de várias melhorias e extensões do DQN, incluindo Double DQN, Dueling DQN, Prioritized Experience Replay e outros. 
<br>Monte Carlo Tree Search (MCTS): Um algoritmo de planejamento e busca baseado em simulações de Monte Carlo para problemas de decisão sequenciais.  
<br>AlphaGo: Um algoritmo desenvolvido pela DeepMind que combina Redes Neurais Convolucionais (CNN), Monte Carlo Tree Search (MCTS) e aprendizado por reforço para jogar o jogo de tabuleiro Go. Ficou famoso ao derrotar o campeão mundial de Go, Lee Sedol, em 2016. 
<br>AlphaZero: Uma evolução do AlphaGo que utiliza aprendizado por reforço auto-supervisionado e busca baseada em MCTS para aprender a jogar vários jogos de tabuleiro, incluindo Go, xadrez e shogi, a partir do zero, sem conhecimento prévio além das regras básicas. 
<br>MuZero: Uma extensão do AlphaZero que combina aprendizado por reforço e planejamento baseado em modelos para aprender a jogar uma variedade de jogos sem conhecimento prévio do modelo dinâmico do ambiente, ou seja, aprendendo apenas a partir das interações com o ambiente. 
<br>Algoritmos de otimização e busca: 
<br>Gradient Descent: Um algoritmo de otimização que minimiza iterativamente uma função objetivo, movendo-se na direção do gradiente negativo. 
<br>Stochastic Gradient Descent: Uma variação do Gradient Descent que atualiza os pesos usando apenas um subconjunto de amostras (ou uma amostra única) a cada iteração, tornando o processo mais rápido e menos suscetível a mínimos locais. 
<br>Momentum: Uma técnica que acelera o Gradient Descent ao adicionar uma fração do vetor de atualização da etapa anterior à atualização atual, ajudando a superar mínimos locais e acelerando a convergência. 
<br>Nesterov Accelerated Gradient: Uma modificação do algoritmo Momentum que oferece uma melhor convergência ao considerar a posição futura aproximada dos pesos antes de calcular o gradiente. 
<br>RMSprop: Um algoritmo de otimização adaptativa que ajusta a taxa de aprendizado de acordo com a magnitude dos gradientes, ajudando a evitar oscilações e a acelerar a convergência. 
<br>AdaGrad: Um algoritmo de otimização adaptativa que ajusta a taxa de aprendizado para cada parâmetro individualmente com base na soma dos gradientes quadrados anteriores. 
<br>AdaDelta: Uma extensão do AdaGrad que busca resolver a redução monótona da taxa de aprendizado, adaptando a taxa de aprendizado com base em uma janela de gradientes passados. 
<br>Adam: Um algoritmo de otimização adaptativa que combina os conceitos do Momentum e do RMSprop, ajustando a taxa de aprendizado e o momento de cada parâmetro individualmente. 
<br>AdamW: Uma variação do algoritmo Adam que introduz uma correção na regularização de pesos, melhorando a convergência e o desempenho em tarefas de aprendizado profundo. 
<br>FTRL: Um algoritmo de otimização online (Follow-The-Regularized-Leader) que é particularmente eficaz para problemas com alta dimensionalidade e esparsidade, como aprendizado de máquina em larga escala. 
<br>Newton-Raphson: Um algoritmo de otimização baseado em métodos de segunda ordem que usa a matriz hessiana (segundas derivadas) da função objetivo para encontrar mínimos locais mais rapidamente do que o Gradient Descent. 
<br>Broyden-Fletcher-Goldfarb-Shanno (BFGS): Um algoritmo de otimização quasi-Newton que usa aproximações da matriz hessiana para encontrar mínimos locais de uma função objetivo, sendo mais eficiente que o método de Newton-Raphson em termos de uso de memória e cálculos. 

### Algoritmos de Otimização Evolutiva 

<br>Algoritmos Genéticos: É um algoritmo genético. 
<br>Particle Swarm Optimization: Algoritmo de otimização baseado em enxames. 
<br>Simulated Annealing: Algoritmo de otimização inspirado no processo de recozimento de metais. 
<br>Hill Climbing: Algoritmo de otimização local. 
<br>Tabu Search: Algoritmo de otimização baseado em meta-heurística. 
<br>Ant Colony Optimization: Algoritmo de otimização inspirado no comportamento das colônias de formigas. 
<br>Bee Algorithm: Algoritmo de otimização inspirado no comportamento das abelhas. 
<br>Cuckoo Search: Algoritmo de otimização inspirado no comportamento de nidificação de algumas espécies de cucos. 
<br>Harmony Search: Algoritmo de otimização inspirado na improvisação musical. 
<br>Differential Evolution: Algoritmo de otimização evolutiva. 
<br>Coordinate Descent: Algoritmo de otimização baseado em busca coordenada. 

### Algoritmos de processamento de linguagem natural (NLP): 

<br>TF-IDF: Medida estatística usada para avaliar a importância de uma palavra em um conjunto de documentos, considerando sua frequência e a frequência inversa do documento. 
<br>Word2Vec: Modelo de aprendizado profundo para gerar representações vetoriais densas de palavras com base em seu contexto. 
<br>GloVe: Modelo de aprendizado profundo para obter representações vetoriais de palavras, baseado na coocorrência de palavras em um corpus. 
<br>FastText: Modelo de aprendizado profundo semelhante ao Word2Vec, mas com suporte para representações subpalavras, o que o torna mais eficiente para palavras raras e morfologicamente ricas. 
<br>BERT: Modelo de linguagem bidirecional baseado no Transformer que aprende representações contextuais para processamento de linguagem natural. 
<br>GPT: Modelo de linguagem unidirecional baseado no Transformer que é treinado para prever a próxima palavra em uma sequência de texto. 
<br>ELMo: Modelo de aprendizado profundo baseado em RNN que gera representações de palavras contextuais usando um modelo de linguagem bidirecional. 
<br>Transformer: Arquitetura de aprendizado profundo para NLP que usa mecanismos de atenção e paralelismo para processar sequências de texto. 
<br>Seq2Seq: Modelo de aprendizado profundo para mapear sequências de entrada em sequências de saída, comumente usados para tradução automática e outros problemas de sequência. 
<br>Attention Mechanism: Técnica que permite que modelos de aprendizado profundo ponderem diferentes partes de uma sequência de entrada ao gerar uma sequência de saída. 
<br>LSTM: Variação de Redes Neurais Recorrentes projetada para lidar com o desaparecimento do gradiente, permitindo o aprendizado de dependências de longo prazo em sequências de texto. 
<br>GRU: Variação simplificada das LSTM que também é projetada para lidar com o desaparecimento do gradiente em sequências de texto. 
<br>OpenAI Codex: Modelo de linguagem de grande escala treinado pela OpenAI, baseado na arquitetura GPT. 
<br>RNN: Redes Neurais Recorrentes, uma classe de redes neurais que processam sequências de dados, como texto ou séries temporais. 
<br>POS Tagging: Tarefa de etiquetar cada palavra em uma sequência de texto com sua respectiva classe gramatical (por exemplo, substantivo, verbo, adjetivo, etc.). 
<br>Named Entity Recognition (NER): Tarefa de identificar e classificar entidades nomeadas (como pessoas, organizações e locais) em um texto. 
<br>Dependency Parsing: Tarefa de analisar a estrutura gramatical de uma frase e estabelecer relações entre as palavras, como sujeito, objeto, etc. 
<br>Sentiment Analysis: Tarefa de determinar a polaridade (positiva, negativa ou neutra) de um texto. 
<br>Text Summarization: Tarefa de criar um resumo conciso e informativo de um texto mais longo. 
<br>Machine Translation: Tarefa de traduzir automaticamente um texto de um idioma para outro usando modelos de aprendizado de máquina ou técnicas de processamento de linguagem natural. 

### Algoritmos de recomendação: 

<br>Collaborative Filtering (User-based, Item-based): 
<br>User-based: Recomenda itens com base nas preferências de usuários similares. 
<br>Item-based: Recomenda itens com base em itens semelhantes que o usuário já gostou. 
<br>Content-based Filtering: Recomenda itens com base nas características dos itens e nas preferências do usuário. 
<br>Hybrid Filtering: Combina métodos de filtragem colaborativa e baseada em conteúdo para fazer recomendações mais precisas. 
<br>Matrix Factorization (SVD, NMF):SVD (Singular Value Decomposition): Decompõe a matriz de interações usuário-item em componentes menores para identificar padrões latentes. NMF (Non-negative Matrix Factorization): Similar ao SVD, mas com a restrição de que todos os valores na matriz devem ser não negativos. 
<br>Alternating Least Squares (ALS): Uma técnica de fatoração de matriz utilizada principalmente em filtragem colaborativa, que otimiza alternadamente os fatores latentes dos usuários e itens. 
<br>Association Rule Mining (Apriori, Eclat, FP-Growth): Apriori, Eclat e FP-Growth são algoritmos usados para descobrir regras de associação entre itens, identificando padrões frequentes de itens que ocorrem juntos. 
<br>Deep Learning-based Recommendations: Utiliza técnicas de aprendizado profundo, como redes neurais, para modelar interações entre usuários e itens e fazer recomendações personalizadas. 

### Algoritmos de detecção de anomalias: 

<br>Isolation Forest: Um algoritmo baseado em árvores que isola as observações anômalas, construindo árvores de decisão aleatórias e usando o comprimento médio do caminho para classificar anomalias. 
<br>Local Outlier Factor (LOF): Mede a densidade local de cada ponto em relação aos seus vizinhos e identifica pontos que têm densidades significativamente menores do que seus vizinhos como anomalias. 
<br>One-Class SVM: Um algoritmo de aprendizado supervisionado que treina um modelo apenas com dados normais e depois classifica novas observações como normais ou anômalas com base na margem aprendida. 
<br>Elliptic Envelope: Um método estatístico que assume que os dados normais seguem uma distribuição Gaussiana multivariada e ajusta uma elipse de confiança para detectar anomalias. 
<br>HBOS (Histogram-based Outlier Score): Estima a probabilidade de uma observação ser anômala com base na distribuição dos dados em histogramas univariados. 
<br>K-means: Um algoritmo de agrupamento que pode ser adaptado para detecção de anomalias, considerando pontos distantes dos centróides do cluster como anômalos. 
<br>DBSCAN: Um algoritmo de agrupamento baseado em densidade que identifica áreas de alta densidade separadas por áreas de baixa densidade e pode classificar pontos em áreas de baixa densidade como anomalias. 
<br>Autoencoders: Redes neurais artificiais que aprendem a compactar e reconstruir os dados, podendo ser usadas para detectar anomalias, identificando pontos com maior erro de reconstrução. 
<br>Variational Autoencoders (VAE): Uma extensão dos autoencoders que inclui uma camada estocástica e pode ser usada para detectar anomalias de forma semelhante aos autoencoders regulares. 
<br>LSTM: Redes neurais recorrentes especializadas em aprender sequências temporais, podem ser treinadas para prever a próxima etapa em uma série temporal e identificar pontos com previsões de baixa precisão como anomalias. 

### Algoritmos de redução de dimensionalidade: 

<br>PCA (Principal Component Analysis): Uma técnica linear de redução de dimensionalidade que busca projetar os dados em um espaço de menor dimensão, mantendo a maior variância possível. 
<br>LDA (Linear Discriminant Analysis): Uma técnica linear de redução de dimensionalidade que busca projetar os dados em um espaço de menor dimensão, maximizando a separação entre classes. 
<br>Kernel PCA: Uma extensão não linear do PCA que utiliza funções de kernel para projetar os dados em um espaço de maior dimensão antes de aplicar o PCA. 
<br>t-SNE (t-Distributed Stochastic Neighbor Embedding): Uma técnica de redução de dimensionalidade não linear que busca preservar as relações de proximidade entre pontos no espaço de menor dimensão. 
<br>UMAP (Uniform Manifold Approximation and Projection): Um algoritmo de redução de dimensionalidade não linear que busca preservar tanto a estrutura local quanto a global dos dados em um espaço de menor dimensão. 
<br>Isomap: Um algoritmo de redução de dimensionalidade não linear que busca preservar as distâncias geodésicas entre os pontos no espaço de menor dimensão. 
<br>Locally Linear Embedding (LLE): Uma técnica de redução de dimensionalidade não linear que busca preservar as relações lineares locais entre pontos no espaço de menor dimensão. 
<br>Multidimensional Scaling (MDS): Um algoritmo de redução de dimensionalidade que busca preservar as distâncias entre os pontos no espaço de menor dimensão. 

### Algoritmos de análise de séries temporais: 

<br>ARIMA (AutoRegressive Integrated Moving Average): Modelo estatístico linear que combina componentes autorregressivos, médias móveis e diferenciação para modelar séries temporais univariadas. 
<br>SARIMA (Seasonal AutoRegressive Integrated Moving Average): Extensão do modelo ARIMA que adiciona componentes sazonais para capturar padrões sazonais nas séries temporais. 
<br>Exponential Smoothing: Família de métodos de previsão que utilizam médias ponderadas de observações passadas, com pesos decrescentes exponencialmente ao longo do tempo. 
<br>Prophet: Modelo desenvolvido pelo Facebook que combina componentes de tendência, sazonalidade e feriados para modelar séries temporais, com foco em desempenho automático e escalabilidade. 
<br>LSTM (Long Short-Term Memory): Tipo de Rede Neural Recorrente (RNN) com unidades de memória capazes de aprender dependências de longo prazo, adequado para modelagem de séries temporais. 
<br>GRU (Gated Recurrent Units): Variação das LSTMs, também pertencente à família das RNNs, com uma estrutura mais simples e menor quantidade de parâmetros, mantendo um bom desempenho na modelagem de séries temporais. 
<br>Bayesian Structural Time Series (BSTS): Modelo de séries temporais que utiliza inferência bayesiana para estimar componentes estruturais, como tendência, sazonalidade e regressores, capturando incertezas nas previsões. 
<br>Hidden Markov Models (HMM): Modelo estatístico baseado em cadeias de Markov que descreve um sistema com estados ocultos, onde as transições entre estados e as emissões de observações são governadas por probabilidades. 
<br>Kalman Filter: Algoritmo recursivo de estimação que combina informações de medições e modelos dinâmicos para estimar estados ocultos em sistemas lineares com ruído. 
<br>Dynamic Time Warping (DTW): Algoritmo de alinhamento temporal que mede a similaridade entre duas séries temporais, permitindo comparações mesmo quando as séries têm variações temporais ou taxas de amostragem diferentes. 

### Algoritmos de análise de redes e grafos: 

<br>PageRank: Algoritmo desenvolvido pelo Google para classificar páginas da web em termos de importância, com base na estrutura de links do grafo da web. 
<br>Shortest Path (Dijkstra, A*, Bellman-Ford): Algoritmos para encontrar o caminho mais curto entre dois nós em um grafo. Dijkstra e A* são adequados para grafos com pesos não negativos, enquanto o Bellman-Ford também funciona com pesos negativos, desde que não haja ciclos negativos. 
<br>Minimum Spanning Tree (Kruskal, Prim): Algoritmos para encontrar a árvore geradora mínima em um grafo conectado e ponderado. Kruskal e Prim são dois algoritmos populares para resolver este problema. 
<br>Community Detection (Louvain, Girvan-Newman): Algoritmos para identificar comunidades ou grupos de nós altamente conectados em um grafo. O método de Louvain é baseado na otimização da modularidade, enquanto o método Girvan-Newman é baseado na remoção de arestas com maior centralidade de intermediação. 
<br>Node2Vec: Algoritmo para aprender representações de nós em um espaço vetorial de baixa dimensão, preservando as propriedades do grafo. 
<br>Graph Convolutional Networks (GCN): Redes neurais baseadas em grafos que operam diretamente na estrutura do grafo para aprendizado semi-supervisionado de classificação de nós ou arestas. 
<br>Graph Attention Networks (GAT): Redes neurais baseadas em grafos que usam mecanismos de atenção para pesar as contribuições dos vizinhos na atualização dos nós. 
<br>GraphSAGE: Algoritmo para aprender representações de nós em grafos grandes e dinâmicos, permitindo a geração de representações de nós não vistos durante o treinamento. 
<br>DeepWalk: Algoritmo que usa caminhadas aleatórias no grafo e técnicas de aprendizado não supervisionado para aprender representações de nós em um espaço vetorial de baixa dimensão. 

### Simulação e modelagem de cenários 

<br>Agent-based modeling (ABM): A modelagem baseada em agentes é uma técnica de simulação usada para modelar o comportamento de agentes individuais, como pessoas, empresas ou animais, e suas interações em um ambiente. Essa abordagem é útil em data science para analisar sistemas complexos e entender como as ações dos agentes levam a padrões emergentes e resultados em nível de sistema. 
<br>System Dynamics: A dinâmica de sistemas é uma abordagem para modelar e simular o comportamento de sistemas complexos ao longo do tempo. Ela utiliza equações diferenciais, fluxos e estoques para representar as interações entre os elementos do sistema e analisar o impacto de políticas ou mudanças no sistema. Essa técnica é relevante em data science para estudar sistemas e prever o comportamento futuro com base em mudanças nos parâmetros do sistema. 
<br>Discrete-event simulation (DES): A simulação de eventos discretos é uma técnica que modela a evolução de um sistema ao longo do tempo, representando eventos que ocorrem em momentos específicos e que alteram o estado do sistema. O DES é usado em data science para analisar sistemas em que os eventos ocorrem de forma discreta e aleatória, como filas de espera, processos de produção e sistemas de transporte. 
<br>Cellular automata: Autômatos celulares são modelos matemáticos que representam sistemas dinâmicos e discretos, nos quais o espaço é dividido em células e cada célula evolui com base em regras simples e locais. Eles podem ser usados em data science para simular fenômenos espaciais e temporais, como crescimento populacional, difusão e propagação de doenças. 
